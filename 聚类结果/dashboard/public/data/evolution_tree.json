{
  "name": "AI创新机制演化树",
  "collapsed": false,
  "children": [
    {
      "name": "Transformer",
      "collapsed": true,
      "symbolSize": 30,
      "itemStyle": {
        "color": "#3b82f6"
      },
      "children": [
        {
          "name": "特定几何/结构创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "LoFTR",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于 Transformer 架构,通过扩展 LoFTR 的训练方法以适应动态作物生长场景,实现了图像配准的改进。",
                "topic": "关键点几何回归"
              }
            },
            {
              "name": "HierTFR",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于Transformer架构,通过分层建模和相关性正则化,实现了自动发音评估,并提出了针对不同语言级别的预训练策略。",
                "topic": "跨语言模式匹配"
              }
            },
            {
              "name": "TransLO",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于Transformer架构,通过将点云投影到2D表面并使用局部Transformer实现线性复杂度,提出了首个基于Transformer的LiDAR里程计网络TransLO。",
                "topic": "3D体素/点特征投影"
              }
            },
            {
              "name": "EfficientQ3M",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于Transformer架构,通过多模态对象查询初始化和模态平衡解码器,提升了3D物体检测的效率和性能。",
                "topic": "3D体素/点特征投影"
              }
            },
            {
              "name": "VNMT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于Transformer架构,通过引入基于归一化流的变分近似后验,提升了变分神经机器翻译的灵活性和性能。",
                "topic": "跨语言模式匹配"
              }
            },
            {
              "name": "Transformer TTS network",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Variant",
                "desc": "基于Transformer和Tacotron2架构,通过引入多头注意力机制替换RNN结构,提高了训练效率和长距离依赖建模能力。",
                "topic": "跨语言模式匹配"
              }
            },
            {
              "name": "RayTran",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于Transformer架构,通过双向注意力机制和特征网格表示,实现了从RGB视频中进行多对象3D姿态估计和形状重建的端到端可训练模型。",
                "topic": "关键点几何回归"
              }
            },
            {
              "name": "PlaneFormer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于Transformer架构,通过应用3D感知平面令牌进行3D推理,实现了从稀疏视图平面到3D重建的新模型。",
                "topic": "3D体素/点特征投影"
              }
            },
            {
              "name": "Music transformer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Variant",
                "desc": "基于Transformer架构,通过改进相对注意力机制,实现了在长序列音乐生成中保持长期结构的能力。",
                "topic": "跨语言模式匹配"
              }
            },
            {
              "name": "EF-Transformer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于Transformer架构,通过翻转查询、键和值条目的顺序来减少误差累积,实现了对参与者行为的推理和预测。",
                "topic": "跨语言模式匹配"
              }
            },
            {
              "name": "SDTP",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于 Transformer 架构,通过周期相关机制和序列分解层,提升了从历史序列中提取特征的能力,用于股票市场指数预测。",
                "topic": "跨语言模式匹配"
              }
            },
            {
              "name": "Transformer NMT model",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于Transformer架构,通过引入交叉注意力丢弃机制和崩溃减少训练方法,实现了在神经机器翻译中同时加深编码器和解码器层数,提升了模型性能。",
                "topic": "跨语言模式匹配"
              }
            },
            {
              "name": "MonoDETR",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于Transformer架构,通过引入深度感知模块和深度引导解码器,实现了单目3D物体检测,无需额外深度标注。",
                "topic": "3D体素/点特征投影"
              }
            },
            {
              "name": "OcTr",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于Transformer架构,通过引入动态八叉树结构和混合位置嵌入,在3D物体检测中实现了从粗到细的全局上下文捕获,同时控制计算复杂度。",
                "topic": "3D体素/点特征投影"
              }
            },
            {
              "name": "DeepSolo",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于Transformer架构,通过引入可学习的显式点查询和单一解码器,实现了端到端文本检测和识别的统一模型。",
                "topic": "3D体素/点特征投影"
              }
            },
            {
              "name": "TA",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "AdapterModel",
                "desc": "基于Transformer架构,通过引入可插拔的主题助手(TA)模块,实现了对Transformer模型的增强,提升了抽象摘要性能。",
                "topic": "跨语言模式匹配"
              }
            },
            {
              "name": "Humor Knowledge enriched Transformer (HKT)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于Transformer架构,通过集成上下文和外部知识,实现了多模态幽默理解的新模型HKT。",
                "topic": "跨语言模式匹配"
              }
            },
            {
              "name": "FAR",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于Transformer架构,通过平衡求解和学习姿态估计,实现了灵活、准确和鲁棒的6DoF相对相机姿态估计。",
                "topic": "关键点几何回归"
              }
            },
            {
              "name": "CapeFormer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于Transformer架构,通过两阶段框架(匹配和校准)实现了类别无关姿态估计,提升了准确性和效率。",
                "topic": "关键点几何回归"
              }
            },
            {
              "name": "FLASH3",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于Transformer架构,通过引入门控注意力单元和线性近似方法,实现了高效的长序列处理,并命名为FLASH3模型。",
                "topic": "跨语言模式匹配"
              }
            }
          ]
        },
        {
          "name": "架构与拓扑创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "DOQ",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于Transformer架构,通过知识蒸馏和Oracle查询实现了人类-物体交互检测模型的性能提升。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "SVGformer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于Transformer架构,通过直接处理连续输入值和操作SVG的几何信息,实现了对轮廓细节和长距离依赖的编码,用于多种下游任务。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "Gaussian-masked Directional (GD) Transformer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于Transformer架构,通过引入高斯掩码方向性变体和双仿射注意力评分器,实现了更快速和准确的中文分词模型。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "CCST",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于Transformer架构,提出了一种新的网络结构CCST,通过多压缩投影和INRP损失函数,将特征压缩到低维空间,以保持高搜索精度并提高效率。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "Mask Auto-Labeler (MAL)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于Transformer架构,通过仅使用边界框注释的条件生成掩码伪标签,实现了高质量的实例分割自动标注。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "CrystalFormer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于Transformer架构,通过引入CrystalFormer这一图变换器模型,结合周期性不变性的鲁棒编码和角度信息捕获策略,提升了晶体材料预测任务的性能。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "Regressing Transformers",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于Transformer架构,通过将地点识别重新定义为回归问题,使用相机视场重叠作为相似性真实标签,实现了数据高效训练和强泛化能力。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "FACT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于Transformer架构,通过引入全注意力跨模态Transformer块,实现了音乐条件化的3D舞蹈动作生成。",
                "topic": "协同注意多流融合"
              }
            },
            {
              "name": "Hidden Markov Transformer (HMT)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于 Transformer 架构,通过将翻译起始时刻建模为隐马尔可夫模型的隐藏事件,实现了更准确的同步机器翻译。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "Superpoint Transformer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于Transformer架构,通过引入超点层次结构和自注意力机制,实现了高效的大规模3D场景语义分割。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "TransLoc4D",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于Transformer架构,通过稀疏卷积和Transformer结构提出了TransLoc4D模型,用于4D雷达地点识别,并引入了MinkLoc4D骨干网络来利用多模态信息。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "StyleSwin",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于 Transformer 和 GAN 架构,通过引入 Swin transformer 和双注意力机制,实现了高分辨率图像生成,提升了生成质量和效率。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "HyperTransformer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于Transformer架构,通过生成卷积神经网络权重,实现了监督和半监督少样本学习。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "Video Frame Interpolation Transformer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于Transformer架构,通过引入局部注意力、时空分离策略和多尺度帧合成方案,实现了内容感知的视频帧插值,提升了性能和效率。",
                "topic": "全局自注意力机制"
              }
            },
            {
              "name": "ViLT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于Transformer架构,通过简化视觉输入处理为无卷积方式,提出了ViLT模型,实现了高效且性能优越的视觉与语言预训练。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "T5",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于 Transformer 架构,通过差分隐私训练和 span corruption 技术,在保持预训练效用和速度的同时,实现了对下游任务的高精度微调。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "Transformer-VQ",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于 Transformer 架构,通过向量量化和新型缓存机制实现了线性时间的高效注意力计算。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "BERT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Model",
                "desc": "基于Transformer架构,通过预训练深度双向表示,实现了在多种自然语言处理任务上的最先进性能。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "StARformer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于Transformer架构,通过引入状态-动作-奖励表示来改进视觉强化学习中的长期建模。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "EXTEND",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于Transformer架构,通过将实体消歧任务重新定义为文本提取问题,提出了EXTEND模型,实现了在数据效率和性能上的显著提升。",
                "topic": "Transformer架构变体"
              }
            }
          ]
        },
        {
          "name": "训练范式与学习策略创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "Worldformer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于预训练语言模型(PLM)和Transformer架构,通过约束解码将动作分解为动词模板和对象,构建了Worldformer模型,用于文本游戏环境中的世界建模。",
                "topic": "自监督迁移学习范式"
              }
            },
            {
              "name": "EDGEFORMER",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于Transformer架构,通过引入参数高效化原则和层适应创新,实现了在设备上序列到序列生成的高效模型。",
                "topic": "参数高效微调策略"
              }
            },
            {
              "name": "LASER",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于 Transformer 架构,通过层选择性秩减少(LASER)方法,在训练后移除权重矩阵的高阶组件,以提升大型语言模型的推理性能。",
                "topic": "参数高效微调策略"
              }
            },
            {
              "name": "TLEG",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于 Transformer 架构,通过线性扩展 learngene 模块实现了灵活生成和初始化不同深度的 Transformer 模型,以支持多样化的下游场景。",
                "topic": "参数高效微调策略"
              }
            },
            {
              "name": "XY-LENT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 Transformer 架构,通过超越英语中心的双语文本和新型采样策略,实现了更参数高效的多语言表示学习模型。",
                "topic": "跨语言嵌入空间对齐"
              }
            },
            {
              "name": "Tuformers",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于Transformer架构,通过引入数据驱动的权重调整机制,实现了在泛化性能或模型效率上的改进。",
                "topic": "参数高效微调策略"
              }
            },
            {
              "name": "DEPTH-ADAPTIVE TRANSFORMER",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于Transformer架构,通过动态调整网络层数和计算量,实现了在保持翻译精度的同时显著减少计算资源使用。",
                "topic": "参数高效微调策略"
              }
            },
            {
              "name": "Adaptive Axis Attention",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于Transformer架构,通过自适应轴注意力方法在微调过程中学习不同层的注意力模式,实现了无需预训练的稀疏注意力优化。",
                "topic": "参数高效微调策略"
              }
            },
            {
              "name": "MemSizer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于Transformer架构,通过低维投影和循环式增量计算,实现了线性时间复杂度和恒定内存复杂度的新模型MemSizer。",
                "topic": "参数高效微调策略"
              }
            },
            {
              "name": "DeepScaleLM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于Transformer架构,通过提出DeepScaleLM初始化与扩展方案,实现了信号传播的稳定,使模型能够训练到1000层深度,并在多个任务中超越浅层模型。",
                "topic": "参数高效微调策略"
              }
            },
            {
              "name": "Evolved Transformer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Variant",
                "desc": "基于 Transformer 架构,通过神经架构搜索和进化算法实现了参数效率和性能的提升。",
                "topic": "参数高效微调策略"
              }
            }
          ]
        },
        {
          "name": "时序与动态创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "Multimodal Tracking Transformer (MTTR)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于Transformer架构,通过多模态处理视频和文本,实现了端到端的可训练模型,简化了参考视频对象分割流程。",
                "topic": "时序一致性传播"
              }
            },
            {
              "name": "Mention Flags (MF)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Variant",
                "desc": "基于 Seq2Seq 和 Transformer 架构,通过引入 Mention Flags 机制来跟踪和确保词汇约束的满足,实现了更高的约束满足率和文本质量,同时降低了运行时间。",
                "topic": "编码器-解码器序列映射"
              }
            },
            {
              "name": "Layout-Aware Transformer (LaTr)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于Transformer架构,通过结合语言和布局信息,提出了Layout-Aware Transformer (LaTr),用于场景文本视觉问答任务,实现了词汇无关解码并提升了鲁棒性。",
                "topic": "时序一致性传播"
              }
            },
            {
              "name": "ReferFormer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于Transformer架构,通过将语言作为查询来直接关注视频帧中的相关区域,实现了端到端的参考视频对象分割。",
                "topic": "时序一致性传播"
              }
            },
            {
              "name": "EmoTx",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于Transformer架构,通过多模态输入(视频、角色、对话)实现了电影场景中情感和心智状态的联合预测。",
                "topic": "时序一致性传播"
              }
            },
            {
              "name": "VISUAL INTENTION FORMER",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于Transformer架构,通过两步Transformer结构实现了对图像序列中视觉意图的分类。",
                "topic": "时序一致性传播"
              }
            },
            {
              "name": "StepFormer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于Transformer架构,通过自监督学习和可学习查询,实现了教学视频中关键步骤的发现和定位。",
                "topic": "时序一致性传播"
              }
            }
          ]
        },
        {
          "name": "生成与分布创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "Time-Agnostic VQGAN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于 3D-VQGAN 和 Transformer 架构,通过时间无关 VQGAN 和时间敏感 Transformer 实现了长视频生成,能够从短片段训练生成数千帧的高质量视频。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "LipFormer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于Transformer架构,通过预学习的面部码本和自适应面部扭曲模块,实现了从音频生成高保真和可泛化的说话人脸视频。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "Transformer-GANs",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Variant",
                "desc": "基于 Transformer 和 GAN 架构,通过结合对抗损失和 Gumbel-Softmax 技巧,提升了符号音乐生成的序列质量和训练稳定性。",
                "topic": "对抗式极大极小博弈策略"
              }
            }
          ]
        }
      ]
    },
    {
      "name": "CNN",
      "collapsed": true,
      "symbolSize": 30,
      "itemStyle": {
        "color": "#3b82f6"
      },
      "children": [
        {
          "name": "架构与拓扑创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "discriminative multi-modal fusion framework",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2016,
                "type": "Model",
                "desc": "基于CNN架构,通过引入新颖的判别性多模态融合框架,同时考虑模态间和模态内相关性,并正则化学习特征以实现判别性和紧凑性。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "Digital Gimbal",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于CNN架构,通过端到端学习曝光时间来聚合短曝光帧,实现了图像稳定和高信噪比估计。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "CNN-FCF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Variant",
                "desc": "基于CNN架构,通过引入因子化卷积滤波器(FCF)和ADMM优化方法,实现了滤波器选择与学习的统一,从而压缩模型。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "Bi-Real net",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2018,
                "type": "Model",
                "desc": "基于CNN架构,通过引入身份快捷连接和特定训练算法,Bi-Real net显著提升了1位CNN的表示能力,并在ImageNet上实现了更高的准确率。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "SpArSe",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Model",
                "desc": "基于CNN架构,通过稀疏架构搜索方法结合神经架构搜索和剪枝,实现了在资源受限微控制器上部署的高精度小模型。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "AdaFM-Net",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Model",
                "desc": "基于CNN架构,通过引入AdaFM层实现了对图像修复任务的连续级别调制,能够处理任意修复级别而无需大量额外参数。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "CrackNet",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2017,
                "type": "Model",
                "desc": "基于CNN架构,通过移除池化层并保持图像尺寸不变,实现了像素级精度的路面裂缝检测。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "Sparse-SourceNet",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2017,
                "type": "Variant",
                "desc": "基于卷积神经网络(CNN)架构,通过引入稀疏性和知识转移,提出了Sparse-SourceNet、Hybrid-TransferNet和Sparse-TargetNet等衍生模型,实现了模型压缩和迁移学习精度的提升。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "pyramid feature attention network (PFAN)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Model",
                "desc": "基于CNN架构,通过引入金字塔特征注意力网络(PFAN),结合上下文感知金字塔特征提取模块和注意力机制,增强了高低层特征在显著性检测中的作用。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "TACNN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2017,
                "type": "Model",
                "desc": "基于CNN架构,通过注意力机制和测试依赖的成对策略,构建了TACNN模型,用于自动预测标准测试中阅读问题的难度。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "SimVP",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于CNN架构,通过端到端训练和MSE损失函数,提出了SimVP模型,实现了高性能视频预测并降低了训练成本。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "Polar Transformer Network",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2018,
                "type": "Model",
                "desc": "基于卷积神经网络(CNN)架构,通过结合空间变换网络和规范坐标表示,提出了Polar Transformer Network(PTN),实现了对平移不变性和旋转、缩放等变性的扩展。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "SC-CNN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2016,
                "type": "Model",
                "desc": "基于CNN架构,通过引入空间约束和邻近集成预测器,实现了细胞核检测和分类的联合优化。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "multi-scale Laplacian pyramid based neural network",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2018,
                "type": "Model",
                "desc": "基于 CNN 架构,通过多尺度拉普拉斯金字塔神经网络和结构保持损失函数,实现了从粗到细的深度图像噪声和空洞减少。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "PlaneSegNet",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Variant",
                "desc": "基于CNN架构,通过引入FF-NMS和残差特征增强模块,实现了快速单阶段实例分割,用于平面区域估计。",
                "topic": "基于区域的提议与池化"
              }
            },
            {
              "name": "Keypoint Message Passing",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于 CNN 和 GCN 架构,通过关键点消息传递方法,在视频行人重识别中实现了改进的表示学习和推理速度。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "Pose-Aware Models (PAMs)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2016,
                "type": "Model",
                "desc": "基于CNN架构,通过使用多个姿态特定模型和渲染人脸图像,实现了在极端姿态变化下的无约束人脸识别。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "Deep Internal Learning",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Model",
                "desc": "基于CNN架构,通过深度内部学习方法,利用视频内部时空块的重现性,实现了零样本时间超分辨率,有效去除运动模糊和混叠。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "Multi-scale continuous CRFs as sequential deep networks",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2017,
                "type": "Model",
                "desc": "基于CNN架构,通过引入连续条件随机场和多尺度融合,提出了一种可端到端训练的序列深度网络模型,用于单目深度估计。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "iTGM layer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Model",
                "desc": "基于CNN架构,通过进化算法自动探索层类型和组合,并引入iTGM层,实现了更高效的空间-时间交互学习,提升了视频架构的准确性和速度。",
                "topic": "层次化空间特征编码"
              }
            }
          ]
        },
        {
          "name": "时序与动态创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "recurrent neural filters",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2018,
                "type": "Model",
                "desc": "基于CNN和RNN架构,通过使用RNN作为卷积滤波器来捕捉语言组合性和长期依赖,提升了自然语言处理任务的性能。",
                "topic": "门控循环信息流"
              }
            }
          ]
        },
        {
          "name": "生成与分布创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "Gaussian Shell Maps",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于GAN和CNN架构,通过引入可关节的多壳层支架和3D高斯渲染原语,实现了高效的3D人体生成。",
                "topic": "对抗式极大极小博弈策略"
              }
            }
          ]
        }
      ]
    },
    {
      "name": "GAN",
      "collapsed": true,
      "symbolSize": 30,
      "itemStyle": {
        "color": "#3b82f6"
      },
      "children": [
        {
          "name": "生成与分布创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "Talk-to-Edit",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于GAN架构,通过建模语义场和弯曲轨迹,实现了细粒度面部编辑的交互式对话系统。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "RoCGAN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Model",
                "desc": "基于GAN架构,通过引入无监督路径增强生成器,使模型在强噪声下输出仍能覆盖目标流形,提升了条件生成对抗网络的鲁棒性。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "F-VAEGAN-D2",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Model",
                "desc": "基于 VAE 和 GAN 架构,通过结合条件生成模型和无条件判别器,实现了在归纳和转导学习设置下的任意样本学习,生成高度判别性的 CNN 特征。",
                "topic": "变分潜变量概率重构"
              }
            },
            {
              "name": "Misgan",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Variant",
                "desc": "基于GAN架构,通过引入完整数据生成器和掩码生成器,实现了从不完整数据中学习,并利用对抗训练进行数据插补。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "ByeGlassesGAN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Model",
                "desc": "基于GAN架构,通过编码器、面部解码器和分割解码器构建了一个新模型,用于自动检测和移除面部图像中的眼镜,同时保持身份特征。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "Energy-based Generative Adversarial Network",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2017,
                "type": "Model",
                "desc": "基于GAN架构,通过将判别器视为能量函数,实现了更稳定的训练和高分辨率图像生成。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "SSD-GAN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Variant",
                "desc": "基于 GAN 架构,通过在判别器中嵌入频率感知分类器,在空间和频谱域测量真实性,以缓解频谱信息丢失问题。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "DA-GAN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2018,
                "type": "Model",
                "desc": "基于GAN架构,通过引入深度注意力机制,实现了实例级别的图像翻译,能够分解翻译任务并在结构化潜在空间中学习实例对应关系。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "ProbGAN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Model",
                "desc": "基于GAN架构,通过引入概率框架和贝叶斯推理方法,实现了对生成器分布的学习,确保与数据分布的一致性。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "DiffusionGAN3D",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于 EG3D 和扩散模型架构,通过结合 3D GAN 和扩散先验,实现了文本引导的 3D 生成和领域自适应。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "DS-GAN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于GAN架构,通过DS-GAN生成逼真小物体,结合分割、修复和混合技术,提升小物体检测性能。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "OpenMR",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于GAN架构,通过General Convolutional Prototype Learning (GCPL) 实现了Open set Material Recognition (OpenMR),用于机器人触觉感知中的开放集材料识别。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "inner space preserving generative pose machine (ISP-GPM)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2018,
                "type": "Model",
                "desc": "基于条件GAN架构,通过引入可解释的低维姿态描述符和多阶段增强沙漏网络,提出了ISP-GPM模型,用于在图像中重新摆姿并保持背景。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "Multi-content GAN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2018,
                "type": "Model",
                "desc": "基于GAN架构,通过端到端堆叠条件GAN模型,在通道中考虑内容和网络层中考虑风格,实现了从少量示例生成多内容图像并进行字体风格迁移。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "Style-Based GAN Encoder",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于 GAN 架构,通过引入特征张量映射,实现了高保真图像和视频重建的编码器变体。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "Gaussian Shell Maps",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于GAN和CNN架构,通过引入可关节的多壳层支架和3D高斯渲染原语,实现了高效的3D人体生成。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "CoordGAN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于GAN架构,通过结构-纹理解耦和坐标变换,提出了CoordGAN模型,能够学习生成图像的密集对应关系。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "PluGeN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于 GAN 和 VAE 等预训练生成模型,通过流式模块解耦潜在表示,实现了多标签条件生成和属性操控。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "AM-GAN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2018,
                "type": "Model",
                "desc": "基于生成对抗网络(GAN)架构,通过激活最大化方法提出了一种新模型AM-GAN,以改进样本质量并引入新评估指标AM Score。",
                "topic": "对抗式极大极小博弈策略"
              }
            },
            {
              "name": "Texturify",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于GAN架构,通过引入面卷积算子和分层4-RoSy参数化,在3D对象表面上生成高质量纹理,无需3D颜色监督或几何图像对应关系。",
                "topic": "对抗式极大极小博弈策略"
              }
            }
          ]
        },
        {
          "name": "架构与拓扑创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "StyleSwin",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于 Transformer 和 GAN 架构,通过引入 Swin transformer 和双注意力机制,实现了高分辨率图像生成,提升了生成质量和效率。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "differentially private federated RNNs",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Model",
                "desc": "基于RNN和GAN架构,通过联邦学习和差分隐私方法,实现了在隐私敏感数据上的有效调试。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "Diffusion-GAN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于GAN架构,通过引入自适应扩散过程和时序相关判别器,实现了更稳定和高效的图像生成。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "STORM-GAN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于GAN架构,通过引入时空任务图嵌入,实现了跨城市人类移动响应的动态估计,能够快速适应新城市和时期。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "hybrid GAN-CNN framework",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于CNN和GAN架构,通过结合生成对抗网络与卷积神经网络,处理时间异构卫星数据,实现了热带气旋强度的实时估计。",
                "topic": "层次化空间特征编码"
              }
            },
            {
              "name": "CL-GAN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于CNN-LSTM和GAN架构,通过集成这两种网络提出了新的异常检测模型CL-GAN,用于检测DoS和僵尸网络攻击。",
                "topic": "Transformer架构变体"
              }
            }
          ]
        }
      ]
    },
    {
      "name": "BERT",
      "collapsed": true,
      "symbolSize": 30,
      "itemStyle": {
        "color": "#3b82f6"
      },
      "children": [
        {
          "name": "架构与拓扑创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "SPREADSHEETCODER",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过引入表格上下文(包括标题和半结构化数据)来预测电子表格公式,实现了更高的预测准确性和用户辅助效果。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "MARBERT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过多任务学习模型实现了微方言识别,显著提升了预测性能。",
                "topic": "双向上下文表征"
              }
            },
            {
              "name": "DialogBERT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于 BERT 架构,通过引入分层 Transformer 和新的训练目标,实现了对话响应生成的改进。",
                "topic": "双向上下文表征"
              }
            },
            {
              "name": "SCIBERT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过在科学出版物语料上进行无监督预训练,提升了科学领域 NLP 任务的性能。",
                "topic": "双向上下文表征"
              }
            },
            {
              "name": "Point-BERT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于 BERT 和 Transformer 架构,通过掩码点建模预训练策略,将 BERT 概念推广到 3D 点云,提升了标准点云 Transformer 的性能。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "BERT-based model",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过引入话语增强的自训练方法,迭代利用未标记数据改进情感事件分类器的性能。",
                "topic": "双向上下文表征"
              }
            },
            {
              "name": "BROS",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过编码文本在二维空间中的相对位置和使用区域掩码策略进行预训练,实现了在关键信息提取任务中不依赖视觉特征的性能提升。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "CogQA",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于 BERT 和图神经网络架构,通过协调隐式提取和显式推理模块构建认知图,实现了大规模多跳问答。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "DRMM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Model",
                "desc": "基于 BERT 和 ResNet 架构,通过交替双注意力机制实现了图像和文本模态特征的深度交互与聚合。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "K-BERT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过注入知识图谱三元组并引入软位置和可见矩阵来克服知识噪声,实现了知识增强的语言表示模型。",
                "topic": "双向上下文表征"
              }
            },
            {
              "name": "SparK",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于BERT和卷积网络架构,通过稀疏卷积和分层解码器实现了掩码图像建模,提升了预训练性能。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "HABERTOR",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过四元数分解组件、多源集成头和正则化对抗训练等手段,实现了更高效的仇恨言论检测模型。",
                "topic": "双向上下文表征"
              }
            },
            {
              "name": "Tribrid",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过引入自动生成的否定视角和联合学习多预测,实现了立场分类性能的提升。",
                "topic": "双向上下文表征"
              }
            },
            {
              "name": "LASERTAGGER",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Variant",
                "desc": "基于 BERT 和 Transformer 架构,通过序列标注方法将文本生成转化为编辑任务,实现了高效和精确的文本编辑。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "type-enhanced BERT (TyBERT)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "AdapterModel",
                "desc": "基于 BERT 架构,通过适配器层集成命名实体类型信息,实现了无需重新训练即可纠正 NER 错误的模型。",
                "topic": "双向上下文表征"
              }
            },
            {
              "name": "BioBERT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过在生物医学语料上进行预训练,实现了在生物医学文本挖掘任务中的显著性能提升。",
                "topic": "双向上下文表征"
              }
            },
            {
              "name": "BEST",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过耦合标记化处理姿态三元组单元,实现了手语识别模型的预训练和微调,提升了性能。",
                "topic": "双向上下文表征"
              }
            },
            {
              "name": "LUT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Variant",
                "desc": "基于预训练的BERT模型,通过三重监督信号解耦端到端语音到文本翻译任务,实现了性能提升。",
                "topic": "双向上下文表征"
              }
            },
            {
              "name": "SplitNER",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过将命名实体识别任务拆分为两个问答子任务并分别微调,实现了高效和性能提升。",
                "topic": "双向上下文表征"
              }
            },
            {
              "name": "SG-Net",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过引入语法引导的自注意力机制和双上下文架构,实现了更好的语言表示和机器阅读理解性能提升。",
                "topic": "双向上下文表征"
              }
            }
          ]
        },
        {
          "name": "训练范式与学习策略创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "SDR",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过新颖的自编码器和量化技术实现了高效的文档表示压缩,提升了信息检索任务的效率。",
                "topic": "师生软标签对齐"
              }
            },
            {
              "name": "PSSM-Distil",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Variant",
                "desc": "基于BERT架构,通过知识蒸馏和对比学习,结合EnhanceNet进行特征增强和分布对齐,实现了在低质量PSSM上的蛋白质二级结构预测。",
                "topic": "师生软标签对齐"
              }
            },
            {
              "name": "CEEBERT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于 BERT 和 ALBERT 架构,通过在线学习算法动态确定样本的早期退出点,实现了跨域推理的加速。",
                "topic": "师生软标签对齐"
              }
            },
            {
              "name": "schuBERT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过优化架构设计维度而非减少编码器层数,实现了更轻量且高效的模型 schuBERT。",
                "topic": "师生软标签对齐"
              }
            },
            {
              "name": "AUTOSUMM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于BERT和GPT-2等大型语言模型,通过神经架构搜索和知识蒸馏技术,开发了自动创建文本摘要深度学习模型的方法,实现了模型压缩和定制化。",
                "topic": "师生软标签对齐"
              }
            },
            {
              "name": "PoWER-BERT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过渐进式词向量消除策略,在保持准确性的同时显著加速推理过程。",
                "topic": "师生软标签对齐"
              }
            },
            {
              "name": "BADGE",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过引入块级旁路和基于分歧的早期退出机制,实现了多出口预训练语言模型的优化,提升了推理速度与性能的权衡。",
                "topic": "师生软标签对齐"
              }
            },
            {
              "name": "distillation model",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于 BERT 架构,通过蒸馏方法构建了一个新的蒸馏模型,在中文机器阅读理解中实现了更快的推理速度和更高的推理准确率。",
                "topic": "师生软标签对齐"
              }
            },
            {
              "name": "ViLBERT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于 ViLBERT 架构,通过在大规模视觉语言数据集上进行预训练并微调于视觉对话任务,实现了性能提升。",
                "topic": "模态指令对齐"
              }
            },
            {
              "name": "SlowBERT",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于BERT架构,通过新的排名替换对抗文本生成算法和时间近似算法,实现了对输入自适应多出口BERT的慢速攻击,显著增加推理成本。",
                "topic": "师生软标签对齐"
              }
            }
          ]
        }
      ]
    },
    {
      "name": "CLIP",
      "collapsed": true,
      "symbolSize": 30,
      "itemStyle": {
        "color": "#3b82f6"
      },
      "children": [
        {
          "name": "训练范式与学习策略创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "Open-VCLIP",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 CLIP 架构,通过插值权重优化方法,将其扩展为开放词汇视频模型,实现了零样本视频识别。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "CAT-Seg",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于 CLIP 架构,通过聚合图像和文本嵌入之间的成本体积,实现了开放词汇语义分割,能够处理可见和不可见类别。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "Vision-to-Language Tokenizer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于大型语言模型(LLM)和CLIP架构,通过引入Vision-to-Language Tokenizer(V2T Tokenizer)将图像转换为语言标记,实现了无需微调的视觉理解和图像恢复能力。",
                "topic": "模态指令对齐"
              }
            },
            {
              "name": "BIKE",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于预训练的CLIP模型,通过双向跨模态知识探索机制,实现了视频识别性能的提升。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "Semantic-Enhanced Image Clustering (SIC)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于视觉语言预训练模型 CLIP 架构,通过映射图像到语义空间和一致性学习,实现了语义增强的图像聚类方法。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "CLIPPING",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于CLIP和MobileViT-v2架构,通过层间对齐的知识蒸馏方法,在视频-语言检索任务中实现了高效模型压缩。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "PLEor",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 CLIP 模型,通过双提示方案和视觉-语言评估器实现了开放集细粒度检索,利用知识蒸馏将类别特定差异转移到骨干网络中。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "FairerCLIP",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于 CLIP 架构,通过在再生核希尔伯特空间中联合去偏图像和文本表示,实现了更公平和鲁棒的零样本预测。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "WinCLIP",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 CLIP 架构,通过窗口级特征提取和组合集成,实现了零样本和少样本异常分类与分割。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "DA-CLIP",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于 CLIP 架构,通过训练一个额外的控制器来适应固定图像编码器,实现了多任务图像恢复,提升了低层视觉任务的性能。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "CLIPSelf",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于CLIP和Vision Transformer架构,通过自蒸馏方法将图像级识别能力适配到局部区域,无需区域-文本对,提升了开放词汇密集预测任务的性能。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "AltCLIP",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 CLIP 和 XLM-R 架构,通过替换文本编码器并使用两阶段训练方法,实现了多语言多模态表示模型的构建。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "ZOC",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于预训练模型 CLIP 架构,通过训练文本图像描述生成器扩展模型,实现了零样本分布外检测。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "MaskCLIP",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于 CLIP 架构,通过最小修改和添加伪标签与自训练,实现了零样本语义分割,在多个数据集上显著提升性能。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "PØDA",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 CLIP 架构,通过提示驱动的实例归一化(PIN)优化源特征变换,实现零样本领域自适应。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "HOICLIP",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 CLIP 架构,通过引入交互解码器和知识集成块,实现了高效知识迁移,提升了人-物交互检测的泛化性能。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "SCTC",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于CLIP模型,通过探索自三元组和跨三元组相关性,构建图结构来聚合特征,并利用知识蒸馏增强交互感知特征,实现了更准确的人类-物体交互检测。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "VL-LTR",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于预训练的视觉-语言模型(如 CLIP 和 ALI-GN),通过引入文本模态学习类级视觉-语言表示,提升了长尾视觉识别性能。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "EclipSE",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于 CLIP 架构,通过添加统一的视听变换器块,实现了高效的长范围文本到视频检索。",
                "topic": "对比式图文预训练"
              }
            },
            {
              "name": "ILA",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于 CLIP 架构,通过隐式可学习对齐方法,在视频识别中实现了高效的时间建模,无需复杂的时间注意力机制。",
                "topic": "对比式图文预训练"
              }
            }
          ]
        },
        {
          "name": "生成与分布创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "Style2Talker",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于CLIP、StyleGAN和3DMM等模型,通过两阶段风格化方法,结合音频、文本和图片输入,实现了高分辨率的情感风格和艺术风格说话头生成。",
                "topic": "对抗式极大极小博弈策略"
              }
            }
          ]
        }
      ]
    },
    {
      "name": "GNN",
      "collapsed": true,
      "symbolSize": 30,
      "itemStyle": {
        "color": "#3b82f6"
      },
      "children": [
        {
          "name": "架构与拓扑创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "L2R-GNN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于图神经网络(GNN)架构,通过引入非线性图去相关方法和双层优化随机算法,提升了在分布偏移下的泛化能力。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "SEA-GWNN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于图神经网络(GNN)架构,通过引入自适应图小波变换和局部提升策略,在保持原始图拓扑的同时增强了节点表示。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "O-GNN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于图神经网络(GNN)架构,通过引入环结构先验和潜在向量表示,增强了分子建模的表达能力。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "Efficient Deep Space Filling Curve",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于图神经网络(GNN)架构,通过定制算法和孪生网络学习方案,实现了高效的空间填充曲线搜索,显著降低了计算成本并支持端到端优化。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "HetSAGE",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于图神经网络(GNN)架构,通过提出HetSAGE模型,有效处理异构图以解决神经符号学习问题,并在多个任务上实现性能提升。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "RG-GLD",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于图神经网络(GNN)和图注意力网络(GAT)架构,通过知识蒸馏和重构图策略,实现了轻量级异常检测。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "DualGraph",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于图神经网络架构,通过结合实例级和分布级关系,设计了一个端到端的训练范式来对抗标签噪声。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "SComGNN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于图神经网络(GNN)架构,通过设计具有低通和中通滤波器的谱图卷积网络以及两阶段注意力机制,有效建模互补关系中的相关性和差异性。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "Spatial-Temporal Fusion Graph Neural Networks (STFGNN)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于图神经网络(GNN)架构,通过融合空间和时间图以及门控卷积模块,实现了交通流预测中隐藏时空依赖的有效学习。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "Greedy Gumbel Neighborhood Aggregator (GNA)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Variant",
                "desc": "基于图神经网络(GNN)架构,通过引入可学习的元聚合器(GNA 和 ANA)来增强二值化 GNN 的表达能力,实现了自适应聚合行为。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "G-TUNING",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于图神经网络(GNN)架构,通过保留下游图的生成模式,提出了一种新的微调方法G-TUNING,以提升迁移学习性能。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "FROND",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于图神经网络(GNN)架构,通过引入分数阶微积分和Caputo分数导数,实现了对长期依赖的捕捉和过平滑问题的缓解。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "CogQA",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Variant",
                "desc": "基于 BERT 和图神经网络架构,通过协调隐式提取和显式推理模块构建认知图,实现了大规模多跳问答。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "PERMGNN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于图神经网络(GNN)架构,通过使用循环、顺序敏感的聚合器和对抗性邻居排列生成器来最小化链接预测损失,实现了更高的表达能力和快速预测。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "Adaptive Kernel Graph Neural Network",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于图神经网络(GNN)架构,通过数据驱动的图核学习机制自适应调整滤波器平衡,实现了对图结构数据的优化表示学习。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "DefGraspNets",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于图神经网络(GNN)架构,提出了DefGraspNets模型,通过学习预测3D应力和变形场,实现了快速梯度优化的抓取规划。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "SEGNO",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于图神经网络(GNN)架构,通过引入二阶连续性和物理归纳偏置,提出了SEGNO模型,以提升在复杂动态系统中的泛化能力。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "hybrid message passing GNN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于图神经网络(GNN)架构,通过引入注意力机制动态图和混合消息传递,实现了对源代码局部和全局结构信息的捕获,用于代码摘要任务。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "GNN with self-supervised pre-training",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于图神经网络(GNN)架构,通过自监督预训练方法提升了脑电图癫痫检测和分类的性能,并引入了定量可解释性方法。",
                "topic": "图拓扑与关系消息传递"
              }
            },
            {
              "name": "ADR-GNN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于图神经网络(GNN)架构,通过引入受平流-扩散-反应系统启发的机制,实现了特征传输、局部平滑和非线性变换的结合,提升了模型性能。",
                "topic": "图拓扑与关系消息传递"
              }
            }
          ]
        }
      ]
    },
    {
      "name": "Diffusion Models",
      "collapsed": true,
      "symbolSize": 30,
      "itemStyle": {
        "color": "#3b82f6"
      },
      "children": [
        {
          "name": "生成与分布创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "AdvDiffuser",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于扩散模型架构,通过扰动预测图像引导潜在代码进入对抗样本空间,实现了自然无限制对抗样本的合成。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "Multiple Conditional Diffusion Model",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于扩散模型架构,通过引入可训练的控制条件编码器和融合网络,结合额外条件实现了对音频生成的细粒度控制。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "pose-guided diffusion model",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于扩散模型架构,通过姿态引导和注意力层设计,实现了从单张图像生成一致长视频的新视角合成。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "Diff3F",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于扩散模型架构,通过从图像基础模型中蒸馏特征到输入形状,实现了对无纹理形状的语义特征描述。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "SDF-Diffusion",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于扩散模型架构,通过使用有符号距离场的连续表示和两阶段生成过程,实现了高分辨率3D形状的生成。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "SADM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于扩散模型架构,通过引入结构引导的对抗训练方法,使模型学习样本间的流形结构,从而在图像生成和跨域微调任务中实现性能提升。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "DDDM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于扩散模型架构,通过直接去噪和引入伪LPIPS损失,实现了高效图像生成,支持少步和多步采样。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "SODA",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于扩散模型架构,通过引入瓶颈结构和自监督目标,实现了强大的表示学习能力。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "DiffusionGAN3D",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于 EG3D 和扩散模型架构,通过结合 3D GAN 和扩散先验,实现了文本引导的 3D 生成和领域自适应。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "LayoutDiffusion",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于扩散模型架构,通过引入结构化图像块和布局融合模块,实现了布局到图像生成的高质量和强可控性。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "LONG-TAILED DIFFUSION MODELS WITH ORIENTED CALIBRATION",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于扩散模型架构,通过加权去噪分数匹配和门控机制,实现了从头部到尾部类的知识转移,以提升长尾分布数据上的生成性能。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "Motion2VecSets",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于扩散模型架构,通过引入4D潜在向量集表示,实现了从点云序列中学习非刚性物体的形状和运动分布,提高了重建精度和泛化能力。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "DiffECC",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于扩散模型架构,通过结合CNN方法和重启采样算法,实现了图像恢复中的误差收缩和校正。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "FlowMDM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于扩散模型架构,通过引入混合位置编码和姿态中心交叉注意力,实现了无缝人类运动组合的生成。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "LFDM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于扩散模型和自编码器架构,通过引入潜在流扩散模型(LFDM)在潜在空间中合成光流序列,实现了条件图像到视频生成,提高了空间细节和时间运动的合成质量与计算效率。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "InstDiffEdit",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于扩散模型架构,通过利用跨模态注意力能力和训练无关的细化方案,实现了高效的图像编辑和快速推理。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "6D-Diff",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于扩散模型架构,通过将2D关键点检测建模为反向扩散过程,并设计基于混合柯西的前向扩散过程,实现了6D物体姿态估计的性能提升。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "Manifold Diffusion Fields",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于扩散模型架构,通过引入流形上的内在坐标系统,实现了在非欧几里得几何中学习连续函数分布的新模型。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "DreamCraft3D",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于扩散模型架构,通过分层生成和引导扩散先验,实现了高保真和一致的3D对象生成。",
                "topic": "迭代去噪扩散过程"
              }
            },
            {
              "name": "Multi-condition Motion Latent Diffusion Model (MCM-LDM)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于扩散模型架构,通过多条件嵌入和运动轨迹、内容与风格的解耦与融合,实现了任意运动风格迁移。",
                "topic": "迭代去噪扩散过程"
              }
            }
          ]
        }
      ]
    },
    {
      "name": "LSTM",
      "collapsed": true,
      "symbolSize": 30,
      "itemStyle": {
        "color": "#3b82f6"
      },
      "children": [
        {
          "name": "特定几何/结构创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "greedy stack LSTM parser",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2016,
                "type": "Variant",
                "desc": "基于 LSTM 架构,通过引入训练探索程序和使用动态预言机,改进了贪婪堆栈 LSTM 依赖解析器,提高了解析准确性。",
                "topic": "句法树结构遍历"
              }
            },
            {
              "name": "distillation parser",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2016,
                "type": "Variant",
                "desc": "基于 LSTM 和 MST 解析器架构,通过蒸馏集成模型并使用结构化铰链损失目标,实现了依赖解析性能的提升。",
                "topic": "句法树结构遍历"
              }
            }
          ]
        },
        {
          "name": "时序与动态创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "QRNN",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Model",
                "desc": "基于RNN和LSTM架构,通过引入四元数代数处理多维特征内部依赖,实现了更优性能和参数效率。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "multilinear trend fuzzy information granule (FIG) within a periodic framework for LSTM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于 LSTM 架构,通过引入多线性趋势模糊信息粒子和周期性框架,解决了长期时间序列预测中的误差累积和低时间相关性问题。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "bidirectional continuous-time LSTM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2019,
                "type": "Variant",
                "desc": "基于 LSTM 架构,通过引入双向连续时间 LSTM 构建可训练提议分布,实现了在连续时间事件流中缺失事件的插补,并改进了粒子滤波方法。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "STL-ALN_BSA-LSTM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于 LSTM 架构,通过季节性趋势分解和自适应学习与基于小生境回溯搜索算法优化权重和阈值,提高了时间序列预测的准确性和可解释性。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "end-to-end spatial and temporal attention model",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2017,
                "type": "Model",
                "desc": "基于RNN和LSTM架构,通过引入空间和时间注意力机制,构建了一个端到端的模型,用于从骨架数据中识别人类动作。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "modified LSTM with jumping",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2017,
                "type": "Variant",
                "desc": "基于 LSTM 架构,通过引入跳跃机制和策略梯度训练,实现了在保持或提高准确性的同时,显著提升处理速度。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "Fast Weight Memory",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于LSTM架构,通过引入快速权重记忆(FWM)实现了关联推理,并通过端到端梯度下降训练在多个任务上表现出色。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "Diagram Parse Graphs (DPG)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2016,
                "type": "Model",
                "desc": "基于 LSTM 架构,通过引入 Diagram Parse Graphs (DPG) 表示和注意力模型,实现了图表的句法解析和问答任务。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "dual-LSTM based approach",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2017,
                "type": "Model",
                "desc": "基于 LSTM 架构,通过引入空间和时间注意力机制,实现了视频视觉问答中的时空推理。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "MD-SEM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Model",
                "desc": "基于LSTM架构,通过多时长训练实现了多时长显著性预测,减少了参数数量并提升了性能。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "S-LSTM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2015,
                "type": "Model",
                "desc": "基于 LSTM 架构,通过扩展到树结构并引入递归过程,提出了 S-LSTM 模型,以处理层次结构中的长距离交互问题。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "neural graph-to-sequence model",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2018,
                "type": "Model",
                "desc": "基于LSTM架构,通过引入新颖的图到序列模型直接编码图级语义,在AMR到文本生成任务中实现了优于现有方法的结果。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "Twin-L2O",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Model",
                "desc": "基于LSTM架构,通过双LSTM框架和课程学习策略,实现了针对极小极大优化问题的首个学习优化模型。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "pose network",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2020,
                "type": "Model",
                "desc": "基于LSTM架构,通过引入卷积LSTM模块和自监督损失,实现了单目视觉里程计中的长期依赖建模。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "Recurrent normalization propagation",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2017,
                "type": "Model",
                "desc": "基于 LSTM 架构,通过参数化方法保持隐藏状态和记忆单元的均值和方差,实现了更高效的训练和推理。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "differential Recurrent Neural Network (dRNN)",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2015,
                "type": "Variant",
                "desc": "基于 LSTM 架构,通过引入微分门控方案和状态导数,实现了对动作识别中时空动态的改进。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "Multi-view recurrent neural acoustic word embeddings",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2017,
                "type": "Model",
                "desc": "基于 LSTM 架构,通过多视图对比损失联合学习声学和字符序列嵌入,实现了改进的词判别性能。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "Cross temporal recurrent networks",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2018,
                "type": "Model",
                "desc": "基于 LSTM 架构,通过交叉应用时间门控机制,实现了对问答对的联合表示学习。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "FDHT-LSTM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Variant",
                "desc": "基于LSTM架构,通过完全分解的层次Tucker结构实现了模型压缩,在保持高精度的同时大幅减少参数数量。",
                "topic": "门控循环信息流"
              }
            },
            {
              "name": "attention-based bidirectional LSTM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2017,
                "type": "Model",
                "desc": "基于 LSTM 架构,通过注意力机制实现了目标依赖情感分类的改进。",
                "topic": "门控循环信息流"
              }
            }
          ]
        },
        {
          "name": "架构与拓扑创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "IoT-Defender",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于 LSTM 架构,通过修改遗传算法进行特征选择和参数微调,实现了在物联网网络中高效检测网络攻击的 IoT-Defender 模型。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "multi-state fusion informer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于 Informer、Transformer 和 LSTM 架构,通过多状态融合和迁移学习实现了金属管弯曲早期起皱预测,提高了准确性和效率。",
                "topic": "Transformer架构变体"
              }
            }
          ]
        }
      ]
    },
    {
      "name": "NeRF",
      "collapsed": true,
      "symbolSize": 30,
      "itemStyle": {
        "color": "#3b82f6"
      },
      "children": [
        {
          "name": "生成与分布创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "ICE-NeRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 NeRF 架构,通过分解感知权重优化和引入 AFR 与 SMR 技术,实现了交互式颜色编辑,提高了多视角一致性和效率。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "Ref-NeRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于 NeRF 架构,通过引入反射辐射表示和正则化法向量,显著提升了镜面反射的真实性和准确性。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "ActorsNeRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 NeRF 架构,通过引入人类先验和特征空间对齐,实现了在少样本条件下对新演员和姿态的泛化渲染。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "JacobiNeRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 NeRF 架构,通过正则化学习动态以对齐高度相关实体的雅可比矩阵,实现了语义互信息最大化,从而提升标注传播效率。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "NeRFLight",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于NeRF架构,通过共享特征网格和区域分割解码器,实现了轻量化和实时渲染。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "F2-NeRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于NeRF架构,通过提出一种新的透视扭曲方法,实现了在网格化NeRF框架中处理任意相机轨迹,并显著加速训练。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "Mega-NeRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于 NeRF 架构,通过几何聚类算法和数据并行化,实现了大规模场景的高效训练和快速渲染。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "VP3D",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于 NeRF 和扩散模型架构,通过引入 2D 视觉提示和可微分奖励函数,提升了文本到 3D 生成的视觉保真度和细节纹理。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "Aug-NeRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Variant",
                "desc": "基于NeRF架构,通过引入三重物理基础的数据增强来提升模型在未见视图中的泛化能力和几何重建质量。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "Switch-NeRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于NeRF架构,通过引入门控网络和稀疏门控混合专家(MoE)设计,实现了端到端的大规模场景分解与优化。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "3D-SceneDreamer",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于 NeRF 和 2D 扩散模型,通过生成式精炼网络和全局 3D 信息聚合,实现了文本驱动的 3D 一致场景生成。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "StegaNeRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 NeRF 架构,通过优化框架实现了在渲染图像中嵌入和检索隐藏信息,同时保持视觉质量不变。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "WaveNeRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于 NeRF 和 MVS 架构,通过集成小波频率分解和混合神经渲染器,实现了无需逐场景优化的可泛化高质量合成。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "NeRFVS",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 NeRF 架构,通过引入几何支架和两种损失函数,提升了室内场景的自由视图合成性能。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "NeuMan",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于NeRF架构,通过训练人类和场景的NeRF模型,从单一视频中学习特定主题细节,实现新颖姿态和视角的高质量渲染。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "BLiRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于神经辐射场(NeRF)架构,通过频带限制和高维信号分解方法,提升了动态场景建模的表达能力和运动定位效果。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "ContraNeRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Model",
                "desc": "基于NeRF架构,通过引入几何感知对比学习和跨视图注意力,实现了合成到真实场景的新视图合成,提升了渲染质量和细节。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "BungeeNeRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2022,
                "type": "Model",
                "desc": "基于NeRF架构,通过渐进式添加块和激活高频通道,实现了在极端多尺度场景中的细节渲染。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "NeWRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Model",
                "desc": "基于NeRF架构,通过集成无线传播特性,构建了一个可训练的神经网络模型,用于无线信道预测。",
                "topic": "隐式神经体素渲染"
              }
            },
            {
              "name": "SeaThru-NeRF",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2023,
                "type": "Variant",
                "desc": "基于 NeRF 架构,通过结合 SeaThru 图像形成模型,开发了适用于散射介质的新渲染模型,能够学习场景信息和介质参数,实现水下场景的清晰视图生成。",
                "topic": "隐式神经体素渲染"
              }
            }
          ]
        }
      ]
    },
    {
      "name": "SVM",
      "collapsed": true,
      "symbolSize": 30,
      "itemStyle": {
        "color": "#3b82f6"
      },
      "children": [
        {
          "name": "决策与搜索创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "GA-SVM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2007,
                "type": "Variant",
                "desc": "基于 SVM 架构,通过集成实值遗传算法自动优化参数,实现了更高的预测精度和泛化能力。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "Power SVM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2012,
                "type": "Variant",
                "desc": "基于 SVM 架构,通过引入样本分类不确定性来约束分类器边界,实现了在少量训练样本下的泛化性能提升。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "dual coordinate descent method",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2008,
                "type": "Model",
                "desc": "基于SVM算法家族,通过引入一种新颖的双坐标下降方法,实现了对大规模线性SVM的高效优化。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "Transductive support vector machines",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2007,
                "type": "Model",
                "desc": "基于支持向量机(SVM)架构,通过将组合优化问题转化为连续可微问题,实现了针对结构化变量的转导学习模型。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "one-class support vector machine (SVM) novelty detection",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2006,
                "type": "Variant",
                "desc": "基于 SVM 算法家族,通过一分类新颖性检测方法,实现了对颅内脑电图癫痫发作的检测,克服了传统方法需要收集癫痫数据和精确标记的局限性。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "E-SVM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2015,
                "type": "Model",
                "desc": "基于 SVM 算法,通过使用单正例和大量负例训练线性 SVM 作为特征编码器,将通用图像特征转换为任务定制特征,并提出了递归扩展 RE-SVM 以进一步提升性能。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "IKSVMs",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2008,
                "type": "Variant",
                "desc": "基于 SVM 架构,通过引入直方图交集核和预计算辅助表,实现了高效的分类器,显著提升了运行速度和内存效率。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "three-stage classifier",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2009,
                "type": "Variant",
                "desc": "基于 SVM 算法家族,通过结合线性、准线性和非线性核,提出了一种新颖的三阶段分类器,用于目标检测。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "adv-SVM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2021,
                "type": "Variant",
                "desc": "基于 SVM 算法,通过对抗训练和双重随机梯度方法,实现了对核 SVM 的快速可扩展对抗训练,提升了其对抗鲁棒性。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "R-SVMμ+",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2013,
                "type": "Variant",
                "desc": "基于支持向量机(SVM)架构,通过引入线性变换和半径-间隔误差界优化,提出了R-SVMμ+和R-SVM+两种变体,实现了凸优化问题,提升了特征选择和分类性能。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "RQA-Bayes-SVM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2024,
                "type": "Variant",
                "desc": "基于支持向量机(SVM)架构,通过贝叶斯优化参数实现了滚动轴承故障诊断的优化模型。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "SimpleMKL",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2008,
                "type": "Model",
                "desc": "基于支持向量机(SVM)架构,通过加权2-范数正则化和稀疏核组合约束,提出了SimpleMKL算法,实现了高效的多核学习。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "SVMTorch",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2001,
                "type": "Variant",
                "desc": "基于 SVM 架构,通过分解算法实现了对大规模回归问题的高效求解。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "hierarchical SVM classifier",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2006,
                "type": "Variant",
                "desc": "基于SVM架构,通过引入精炼评估方案,将分层SVM分类器转化为贝叶斯最优分类器的近似器。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "MVDG",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2015,
                "type": "Model",
                "desc": "基于SVM架构,通过多视图特征和低秩表示学习,结合正则化器实现领域泛化,并扩展到领域适应。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "Hierarchical spatio-temporal context modeling",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2009,
                "type": "Model",
                "desc": "基于SVM算法家族,通过分层建模时空上下文信息,利用马尔可夫过程提取特征,实现了动作识别性能的提升。",
                "topic": "基于间隔的边界最大化"
              }
            },
            {
              "name": "Multiclass capped p-norm SVM",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2017,
                "type": "Variant",
                "desc": "基于 SVM 架构,通过引入 capped p-norm 损失函数来处理噪声数据,实现了更鲁棒的多类分类。",
                "topic": "基于间隔的边界最大化"
              }
            }
          ]
        },
        {
          "name": "架构与拓扑创新",
          "collapsed": true,
          "symbolSize": 20,
          "itemStyle": {
            "color": "#8b5cf6"
          },
          "children": [
            {
              "name": "hybrid system",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2006,
                "type": "Model",
                "desc": "基于卷积网络和SVM架构,通过结合卷积网络的特征学习和SVM的分类能力,构建了一个混合系统,在通用对象识别任务中实现了更低的错误率。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "constrained support vector machine (SVM) regression",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2001,
                "type": "Variant",
                "desc": "基于支持向量机(SVM)算法,通过引入约束回归和薄板核,实现了非刚性形状变形,改进了基于地标的形状变形方法。",
                "topic": "Transformer架构变体"
              }
            },
            {
              "name": "structural SVM-based Korean word spacing method",
              "symbolSize": 12,
              "itemStyle": {
                "color": "#10b981"
              },
              "attributes": {
                "year": 2014,
                "type": "Variant",
                "desc": "基于结构SVM架构,通过利用输入句子的空格信息,实现了更准确的韩语分词方法。",
                "topic": "Transformer架构变体"
              }
            }
          ]
        }
      ]
    }
  ]
}